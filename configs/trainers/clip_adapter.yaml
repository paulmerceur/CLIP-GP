name: clip-adapter
BASE_CONFIG: configs/trainers/default.yaml

# Dataset root
root: /mnt/features/VDATA/

# Datasets
datasets: [caltech101, oxford_pets, oxford_flowers, fgvc_aircraft, ucf101, food101, stanford_cars, eurosat, dtd]
# datasets: [caltech101]

# Seeds and shots
seeds: [1, 2, 3, 4, 5]
shots: [1, 2, 4, 8, 16, 32]

# Output directory template
template: "{experiment}/{dataset}/CLIP-Adapter_{shots}shots{sig}/seed{seed}"

# Hyperparameters grid
grid:
  {}

TRAINER_NAME: CLIP-Adapter

TRAINER:
  ADAPTER:
    # CLIP-Adapter defaults from paper/code
    CLIP_ADAPTER_REDUCTION: 4   # bottleneck reduction
    CLIP_ADAPTER_RATIO: 0.2     # blend ratio
    CLIP_ADAPTER_OPTIMIZER: adam
    CLIP_ADAPTER_LR: 0.001
    CLIP_ADAPTER_EPOCHS: 100
    CLIP_ADAPTER_USE_TEMPLATE_WEIGHT_TRAINING: False
    USE_GP: False


